{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "    \n",
    "def chunk_prompt_maker(text_pair):\n",
    "    full_text, chunk_text = text_pair\n",
    "    prompt_message = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"\"\"\n",
    "You are an NLP model specialized in threat intelligence extraction. Your task is to extract a knowledge graph related to cybersecurity threats from a given threat intelligence report or blog article, including entities (nodes) and relationships (edges) among those entities, and output the results in a specified format.\n",
    "[Entities (Nodes)]\n",
    "What's an entity:\n",
    "\n",
    "In cyber threat intelligence, \"entity\" refers to any unit of information that can be independently identified, described, and analyzed, and it forms a fundamental component of each link in threat activity. It is important to note that entities here are not limited to those verified indicators (IOCs) specifically used for detection, such as specific IP addresses, domain names, or file hashes, but a broader concept. Entities can be objects with clear names and characteristics (such as \"get-logon-history.ps1\"), or data objects such as \"RAR file\", even if it has no fixed naming rules.\n",
    "\n",
    "The main characteristics of entities are:\n",
    "\n",
    "    Independence: Each entity exists as an independent unit of information and can be extracted and analyzed separately;\n",
    "\n",
    "    Relevance: There may be inherent connections between entities, and by associating this information, a complete attack chain or threat portrait can be constructed;\n",
    "\n",
    "    Diversity: Entities can cover various forms of information such as files, scripts, configuration files, registry entries, network traffic data, log records, etc.;\n",
    "\n",
    "    Contextual significance: Even if an entity (such as a downloaded \"RAR file\") does not have a specific name, as long as it has contextual significance and analytical value in threat intelligence analysis, it is still a valid entity.\n",
    "\n",
    "Important Note\n",
    "\n",
    "    Only extract entities from named entities that directly appear in the current chunk, i.e., only pay attention to the entities explicitly mentioned in the current chunk.\n",
    "\n",
    "    In the process of relationship extraction, if it is discovered that an entity in the current chunk has a relationship with an entity that does not directly appear in the chunk (for example, through indefinite pronouns, chapter hints, or contextual implications), then add that outside-chunk entity to the entity list and extract the corresponding relationship.\n",
    "\n",
    "Entity Extraction Steps\n",
    "Stage 1 – Entity Extraction and Classification\n",
    "\n",
    "Stage 1.1 Fully scan the #current chunk's text# to identify all entities related to cybersecurity threats, including:\n",
    "\n",
    "    Explicitly named indicators (IPs, domains, filenames, hash values, etc.)\n",
    "\n",
    "    Implicit threat components (attack stages, undocumented tools, generic file types)\n",
    "\n",
    "    Contextually significant objects (\"RAR file\", \"registry entry\") even without specific names\n",
    "\n",
    "Stage 1.2 – Type Assignment\n",
    "\n",
    "    Assign one predefined category to each entity.\n",
    "\n",
    "    Use threat-actor/intrusion-set formatted names for unnamed attackers/attacks.\n",
    "\n",
    "    Apply other category only when no predefined type matches.\n",
    "\n",
    "Stage 1.3 – Alias & Lineage Handling\n",
    "\n",
    "    Record all aliases or alternative names for entities.\n",
    "\n",
    "    Identify evolutionary relationships for the \"mother entity\" field (e.g., malware variants).\n",
    "\n",
    "Stage 1.4 – Recheck (Self-Reflection on Completeness)\n",
    "Before finalizing entity extraction, pause and critically reflect on whether any relevant entities may have been overlooked.\n",
    "First, check if any explicitly named entities were unintentionally ignored.\n",
    "Then, examine whether non-explicitly named entities have been missed—these may be referenced using generic terms like file, image, or script, but actually point to specific entities in context.\n",
    "\n",
    "Predefined entity types for categorization:\n",
    "\n",
    "    threat-actor\n",
    "    Individuals, groups, or organizations involved in cyberattacks, such as hacker groups or APT organizations.\n",
    "\n",
    "        If a specific attacker is mentioned but not named, use the format as the entity name: Attacker(using: if no attacker is mentioned, specify the malware/threat_tool used). Example: Attacker(using: EternalBlue)\n",
    "\n",
    "    campaign\n",
    "    A series of attack actions with specific objectives and a timeframe, such as nation-state hacker campaigns.\n",
    "\n",
    "    intrusion-set\n",
    "    A set of attack activities with common goals and tactics, techniques, and procedures (TTPs), usually executed by a specific threat actor.\n",
    "\n",
    "        If a specific attack is mentioned but not named, use the format as the entity name: Attacking(from: specific attacker) or Attacking(using: if no attacker is mentioned, specify the malware/threat_tool used). Example: Attacking(from: APT1), Attacking(using: EternalBlue)\n",
    "\n",
    "    malware\n",
    "    Any software used to disrupt systems, steal data, or perform malicious activities, such as viruses or ransomware.\n",
    "\n",
    "    hacker-tool\n",
    "    Software specifically designed for cyberattacks and used by threat actors to execute malicious tasks. This includes hacking tools and penetration testing tools (e.g., Mimikatz, Metasploit) that were originally created with offensive cyber capabilities in mind.\n",
    "\n",
    "    detailed-part-of-malware/tool\n",
    "    Descriptions of the internal details of malware or tools, such as function names, component names, or module names.\n",
    "\n",
    "    general_entity\n",
    "    Entities related to cyberattacks that are not inherently malicious but are exploited during such activities. This includes components, software, or parts of tools (like functions or modules) that were originally designed for general use but are repurposed in cyberattack scenarios.\n",
    "\n",
    "    indicator\n",
    "    Characteristics used to detect or identify malicious activity, such as malicious URLs, IP addresses, and hash values.\n",
    "\n",
    "    file\n",
    "    A file object in a computer, used to describe malware or infected files.\n",
    "\n",
    "    ipv4-addr\n",
    "    An IPv4 address, which can be used to describe attack origins or C2 servers.\n",
    "\n",
    "    ipv6-addr\n",
    "    An IPv6 address, similar to ipv4-addr but used for modern IP protocols.\n",
    "\n",
    "    domain-name\n",
    "    A network domain name used to describe malicious websites or C2 servers.\n",
    "\n",
    "    course-of-action\n",
    "    Recommended defensive strategies or remediation measures, such as blocking IPs or updating antivirus software.\n",
    "\n",
    "    url\n",
    "    A webpage address, usually used to describe phishing sites or malicious links.\n",
    "\n",
    "    attack-pattern\n",
    "    Describes the strategies and techniques used by attackers or malware, such as phishing attacks or SQL injection.\n",
    "\n",
    "    vulnerability\n",
    "    A security flaw in a computer or software that can be exploited by attackers, such as CVE-2023-1234.\n",
    "\n",
    "    observed-data\n",
    "    Recorded events in a network or system, such as file executions or IP access logs.\n",
    "\n",
    "    location\n",
    "    Describes geographic locations, such as countries, cities, or organizational addresses, which may be linked to threat actors or attacks.\n",
    "\n",
    "    identity\n",
    "    Describes individuals, organizations, or companies, which can be used to identify victims or intelligence sources.\n",
    "\n",
    "    infrastructure\n",
    "    Hardware or software resources utilized to facilitate malicious activities, including but not limited to C2 servers, phishing sites, and other attack-enabling components. If the entity has a concrete identifier, such as a URL, IPv4 address, IPv6 address, or domain name, use the corresponding specific type instead of this generic category.\n",
    "\n",
    "    other\n",
    "    Any other entities related to cyber threats; you should list the entity under this type if none of the above fits.\n",
    "\n",
    "Stage 2 – Relationship Extraction and Classification\n",
    "\n",
    "Stage 2.1 Extract direct and indirect relationships (rel) among entities in the current chunk and classify them into predefined relationship types (rel_type).\n",
    "\n",
    "    The value of “rel” should be taken from the text of the chunk (simplified if necessary).\n",
    "\n",
    "    The value of “rel_type” should be chosen from the predefined relationship types provided in the Predefined 'rel_type' supplement. If there is no match, categorize as “other.”\n",
    "    \n",
    "    Pay attention! The value of 'rel' should be derived directly from the original text to maintain accuracy and traceability. Only in cases where the original text is too long or complex, you can simplify it, and only if the relationship is not explicitly stated in the text, you can use a 'rel_type' as the 'rel' based on the context. In most cases, the 'rel' should not as the same as the 'rel_type'. \n",
    "\n",
    "Stage 2.2 If an entity in the current chunk has a relationship with an entity not directly mentioned in the chunk, but in the full text part(e.g., through indefinite pronouns, chapter references, or context hints), add that outside-chunk entity to the entity list and extract the corresponding relationship. A common example is current chunk has a list of multiple urls/hashs/filename/domains with out any specific relationship, but you should think if the list of entities has a relationship with the topic threat entity. And the listing means the those \"entities\" are related to the topic threat entity with 'indicates' or 'characterizes' relationship.\n",
    "\n",
    "Stage 2.3 – Recheck\n",
    "Ensure that every entity extracted in Stage 1 has at least one corresponding relationship description. There must not be an entity listed without any relationship.\n",
    "If necessary, infer that the entity might have some indirect relationship with another entity in the chunk. Otherwise, that entity might be related to a main entity in the broader text (e.g., an APT, Malware, Threat Actor, Vulnerability, etc.) that was introduced outside the current chunk. In that case, add the main entity (from outside the chunk) to the current chunk’s entity list and extract their relationship.\n",
    "\n",
    "Stage 2.4 – Attack Tactic Classification\n",
    "Based on the MITRE ATT&CK framework, determine which phase(s) of the attack each relationship corresponds to (e.g., Reconnaissance, Initial Access, etc.). One or multiple phases can be assigned; if it cannot be determined or does not apply, use [\"other\"].\n",
    "\n",
    "Supplement: Predefined 'rel_type'\n",
    "\n",
    "    indicates\n",
    "\n",
    "        Used when an indicator (e.g., IP address) points to an attack pattern or malware, meaning the indicator can be used to detect the threat.\n",
    "\n",
    "        Example: An IP address (indicator) indicates (indicates) a malware.\n",
    "\n",
    "    characterizes\n",
    "\n",
    "        Links observed data to a STIX object, meaning the observed data describes the object's behavior.\n",
    "\n",
    "        Example: An observed-data characterizes (characterizes) an attack-pattern.\n",
    "\n",
    "    dynamic-analysis-of\n",
    "\n",
    "        Represents dynamic analysis of malware.\n",
    "\n",
    "        Example: A malware-analysis tool dynamic-analysis-of some malware.\n",
    "\n",
    "    analysis-of\n",
    "\n",
    "        Represents an analysis based on another object (e.g., malware, tools).\n",
    "\n",
    "        Example: A malware-analysis tool dynamic-analysis-of some malware or a malware analysis the target's network.\n",
    "\n",
    "    authored-by\n",
    "\n",
    "        Indicates a STIX object was created by an identity.\n",
    "\n",
    "        Example: A malware is developed by a hacker group.\n",
    "\n",
    "    attributed-to\n",
    "\n",
    "        Indicates an attack activity, malware, or infrastructure is attributed to a threat actor.\n",
    "\n",
    "        Example: intrusion-set attributed-to threat-actor.\n",
    "\n",
    "    controls\n",
    "\n",
    "        Indicates an entity controls another entity, often used for infrastructure and tools.\n",
    "\n",
    "        Example: threat-actor controls C2 server.\n",
    "\n",
    "    exfiltrate-to\n",
    "\n",
    "        Indicates data was stolen and transmitted to a target.\n",
    "\n",
    "        Example: malware exfiltrate-to server.\n",
    "\n",
    "    delivers\n",
    "\n",
    "        Indicates an attack object (e.g., phishing email) delivered malware or tools.\n",
    "\n",
    "        Example: attack-pattern delivers malware.\n",
    "\n",
    "    consists-of\n",
    "\n",
    "        Indicates an object consists of multiple subcomponents.\n",
    "\n",
    "        Example: A malware consists-of multiple modules and functions.\n",
    "\n",
    "    uses\n",
    "\n",
    "        Indicates an entity uses another entity to conduct attacks.\n",
    "\n",
    "        Example: threat-actor uses tool.\n",
    "\n",
    "    owns\n",
    "\n",
    "        Indicates an identity owns an infrastructure.\n",
    "\n",
    "        Example: hacker group owns server.\n",
    "\n",
    "    located-at\n",
    "\n",
    "        Indicates the geographic location of an entity.\n",
    "\n",
    "        Example: C2 server located-at a country.\n",
    "\n",
    "    mitigates\n",
    "\n",
    "        Indicates a defense measure mitigates an attack.\n",
    "\n",
    "        Example: patch mitigates vulnerability.\n",
    "\n",
    "    has\n",
    "\n",
    "        Indicates an object has a specific component.\n",
    "\n",
    "        Example: malware has backdoor feature.\n",
    "\n",
    "    originates-from\n",
    "\n",
    "        Indicates an attack originates from a location.\n",
    "\n",
    "        Example: attack-pattern originates-from Russia.\n",
    "\n",
    "    variant-of\n",
    "\n",
    "        Indicates an entity is a variant of another entity.\n",
    "\n",
    "        Example: ransomware variant-of malware family.\n",
    "\n",
    "    static-analysis-of\n",
    "\n",
    "        Indicates static analysis of malware.\n",
    "\n",
    "        Example: malware-analysis static-analysis-of malware.\n",
    "\n",
    "    investigates\n",
    "\n",
    "        Indicates an object investigates another object.\n",
    "\n",
    "        Example: report investigates threat-actor.\n",
    "\n",
    "    targets\n",
    "\n",
    "        Indicates the target of an attack.\n",
    "\n",
    "        Example: malware targets bank.\n",
    "\n",
    "    compromises\n",
    "\n",
    "        Indicates an entity compromised a system.\n",
    "\n",
    "        Example: APT attack compromises government network.\n",
    "\n",
    "    exploits\n",
    "\n",
    "        This relationship type is used when one entity exploits or attacks the vulnerability or defect of another entity, or when the target entity itself is a vulnerability-type entity.\n",
    "    \n",
    "    other\n",
    "\n",
    "        If a relationship exists but does not fit into the categories above.\n",
    "\n",
    "    \n",
    "\n",
    "Supplement: Predefined 'tactic'\n",
    "    **Reconnaissance**  \n",
    "    Before launching an attack, the attacker gathers information about the target—such as organizational structure, public-facing services, and employee details—to support planning.\n",
    "\n",
    "    **Resource Development**  \n",
    "    The attacker prepares tools and infrastructure, such as malicious domains, phishing sites, malware, or fake identities.\n",
    "\n",
    "    **Initial Access**  \n",
    "    The attacker gains entry into the target system through methods like phishing, exploiting vulnerabilities, or malicious attachments.\n",
    "\n",
    "    **Execution**  \n",
    "    Malicious code or scripts are executed on the compromised system to initiate further attack steps.\n",
    "\n",
    "    **Persistence**  \n",
    "    Techniques are used to maintain access over time, such as backdoors, configuration changes, or scheduled tasks.\n",
    "\n",
    "    **Privilege Escalation**  \n",
    "    The attacker gains higher-level access by exploiting flaws or misconfigurations to obtain admin-level control.\n",
    "\n",
    "    **Defense Evasion**  \n",
    "    Security mechanisms are bypassed using tactics like code obfuscation, log deletion, or abuse of legitimate tools.\n",
    "\n",
    "    **Credential Access**  \n",
    "    User credentials (e.g., passwords or tokens) are stolen or cracked to expand access within the environment.\n",
    "\n",
    "    **Discovery**  \n",
    "    The attacker maps the internal network, systems, and security controls to plan further movement.\n",
    "\n",
    "    **Lateral Movement**  \n",
    "    The attacker uses compromised accounts or tools to move across systems within the network.\n",
    "\n",
    "    **Collection**  \n",
    "    Sensitive data is gathered from the compromised environment for later use or exfiltration.\n",
    "\n",
    "    **Command and Control**  \n",
    "    The attacker communicates with infected systems through external servers to issue commands or extract data.\n",
    "\n",
    "    **Exfiltration**  \n",
    "    Stolen data is transmitted out of the target environment to an external system controlled by the attacker.\n",
    "\n",
    "    **Impact**  \n",
    "    The attacker causes disruption or damage, such as encrypting data, deleting files, or halting operations.\n",
    "\n",
    "\n",
    "Stage 3 – Output Generation\n",
    "[Normalization of Obfuscated URLs, IPs, and Emails]\n",
    "\n",
    "Obfuscated URLs, IP addresses, and email addresses must be converted to their original format:\n",
    "\n",
    "    Replace [.] with . in URLs and IPs (e.g., 192[.]168[.]1[.]1 → 192.168.1.1).\n",
    "\n",
    "    Replace # with @ and [.] with . in emails (e.g., contact#example[.]com → contact@example.com).\n",
    "\n",
    "    Only apply this to URLs, IPs, and emails—leave other obfuscations unchanged.\n",
    "\n",
    "Both the entity list and the relationship list must strictly follow the formats below. Ensure the entity names are consistent in both the entity list and the relationships, and use correct JSON formatting:\n",
    "Part 1: Entity List\n",
    "\n",
    "    The entire JSON array must be strictly enclosed between #Entity_List_Start# and #Entity_List_End#.\n",
    "\n",
    "    Each entity node must include the following attributes (all attribute values should be strings or string arrays):\n",
    "\n",
    "        name: The specific name of the entity.\n",
    "\n",
    "        type: The category of the entity (each entity node must have only one type value).\n",
    "\n",
    "        alias: The alias name of the entity mentioned in the text.\n",
    "\n",
    "            If multiple aliases exist, format as [\"Alias1\", \"Alias2\"].\n",
    "\n",
    "            If there is only one, format as [\"Actual_Value\"].\n",
    "\n",
    "            If none, use [\"None\"].\n",
    "\n",
    "        mother entity: If the entity is a variant or evolution of another entity, provide the name of its parent entity; otherwise, use [\"None\"].\n",
    "\n",
    "Part 2: Entity Relationships\n",
    "\n",
    "    Extract relationship descriptions between entities from the text and output them as a JSON array of objects, with keys sub, rel, rel_type, tactic, and obj.\n",
    "\n",
    "    The entire JSON array must be strictly enclosed between #Relationship_List_Start# and #Relationship_List_End#.\n",
    "\n",
    "    Each relationship object must follow this format:\n",
    "\n",
    "    {\n",
    "        \"sub\": \"<Source Entity>\",\n",
    "        \"rel\": \"<Relationship Text>\",\n",
    "        \"rel_type\": [\"<Relationship Type Category>\"],\n",
    "        \"tactic\": [\"<Tactic Category>\"],\n",
    "        \"obj\": \"<Target Entity>\"\n",
    "    }\n",
    "\n",
    "        sub: Must exactly match the source entity name extracted in Part 1.\n",
    "\n",
    "        rel: A verb or phrase summarizing the relationship as described in the text (if the original text is long, it can be simplified).\n",
    "\n",
    "        rel_type: An array listing one or more of the predefined relationship types (e.g., \"uses\", \"targets\"). Even if there is only one, it should still be formatted as an array.\n",
    "\n",
    "        tactic: A string array representing the mapped attack tactic(s). It can contain zero, one, or multiple categories. Use [\"other\"] if unrecognized.\n",
    "\n",
    "        obj: Must exactly match the target entity name extracted in Part 1.\n",
    "\n",
    "Below is an example:\n",
    "\n",
    "#Entity_List_Start#\n",
    "```json\n",
    "[\n",
    "  { \"name\": \"exampleAPT\", \"type\": \"threat-actor\", \"alias\": [\"exampleAPTnickname\"], \"mother entity\": [\"None\"] },\n",
    "  { \"name\": \"exampleTool\", \"type\": \"hacker-tool\", \"alias\": [\"None\"], \"mother entity\": [\"None\"] },\n",
    "  { \"name\": \"exampleCVE\", \"type\": \"vulnerability\", \"alias\": [\"None\"], \"mother entity\": [\"None\"] }\n",
    "]\n",
    "\n",
    "#Entity_List_End#\n",
    "\n",
    "#Relationship_List_Start#\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"sub\": \"exampleAPT\",\n",
    "    \"rel\": \"utilized\",\n",
    "    \"rel_type\": [\"uses\"],\n",
    "    \"tactic\": [\"Lateral Movement\"],\n",
    "    \"obj\": \"exampleTool\"\n",
    "  },\n",
    "  {\n",
    "    \"sub\": \"exampleTool\",\n",
    "    \"rel\": \"is using\",\n",
    "    \"rel_type\": [\"exploits\"],\n",
    "    \"tactic\": [\"Execution\", \"Privilege Escalation\"],\n",
    "    \"obj\": \"exampleCVE\"\n",
    "  },\n",
    "  {\n",
    "    \"sub\": \"exampleAPT\",\n",
    "    \"rel\": \"leverages vulnerability\",\n",
    "    \"rel_type\": [\"exploits\"],\n",
    "    \"tactic\": [\"other\"],\n",
    "    \"obj\": \"exampleCVE\"\n",
    "  }\n",
    "]\n",
    "\n",
    "#Relationship_List_End#\n",
    "Now, here is the full text of the article and the current chunk of text. Please extract the entities and relationships according to the above rules:\n",
    "\"\"\"+str(full_text)+\"\"\"\n",
    "The current chunk of text is:\n",
    "\"\"\"+str(chunk_text)+\"\"\"\n",
    "\"\"\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    return prompt_message\n",
    "\n",
    "def merger_prompt_maker(merged_text):\n",
    "    prompt_message = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"\"\"\n",
    "You are working on merging results from a distributed knowledge graph construction task for cybersecurity threat intelligence. Before your work, a single article was split into multiple chunks, and each chunk has gone through entity and relationship extraction. Now, you need to merge the processing results of these chunks to form a complete knowledge graph.\n",
    "\n",
    "Your core task: Please merge the results of multiple chunks according to the following strict rules:\n",
    "\n",
    "### Merging Rules\n",
    "1. Entity Merging:\n",
    "   - Consider two entities the same if either:\n",
    "     a) Their names are identical or semantically equivalent (including case differences).\n",
    "   - Merging Strategy:\n",
    "     * Keep the simplest naming format (e.g., \"APT28\" and \"APT28 (Fancy Bear)\" merge into the former, while \"APT28\" adds an attribute `\"alias\": [\"Fancy Bear\"]`), and add a relationship:  \n",
    "       `\"sub\": \"APT28\", \"rel\": \"variant of\", \"rel_type\": [\"variant-of\"], \"tactic\": [\"other\"], \"obj\": \"Fancy Bear\"`.\n",
    "     * Merge all alias lists (removing duplicates).\n",
    "     * Merge all mother entity relationships (keep the most complete evolution chain).\n",
    "\n",
    "2. Relationship Merging:\n",
    "   - Only merge relationships if all the following conditions are met:\n",
    "     a) The subject (sub) is the same after entity merging.\n",
    "     b) The object (obj) is the same after entity merging.\n",
    "     c) The relationship description (rel) is exactly the same text.\n",
    "     d) Differences in 'rel_type' and 'tactic' are ignored for the merging condition.\n",
    "   - Merging Strategy:\n",
    "     * Relationships with different rel_type or tactic remain as separate entries or, if merged, preserve their union.\n",
    "     * Maintain the complete original relationship description.\n",
    "\n",
    "3. Special Handling:\n",
    "   - Only perform merging; all unique entities and relationships must be retained.\n",
    "   - Cross-chunk implied relationships (inferred through mother entities) must be explicitly created.\n",
    "   - Ensure the final result contains all original information, only eliminating redundant expressions.\n",
    "\n",
    "### Output Requirements\n",
    "Maintain the same JSON structure as the original, but:\n",
    "1. Streamline the entity list according to the merging rules.\n",
    "2. Streamline the relationship list according to the merging rules.\n",
    "3. Retain all aliases and mother entity relationships.\n",
    "4. Keep all distinct relationship descriptions.\n",
    "5. The tactic field is similar to the rel_type field; preserve all unique values.\n",
    "\n",
    "Please strictly output the final merged results in the following format:\n",
    "\n",
    "### [Final Entity List]\n",
    "#Final_Entity_List_Start#\n",
    "json\n",
    "[\n",
    "  {\n",
    "    \"name\": \"<standardized name>\",\n",
    "    \"type\": \"<best classification>\",\n",
    "    \"alias\": [\"<original name 1>\", \"<alias 2>\", ...],\n",
    "    \"mother entity\": [\"<complete mother entity chain>\"]\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "#Final_Entity_List_End#\n",
    "\n",
    "### [Final Relationship List]\n",
    "#Final_Relationship_List_Start#\n",
    "json\n",
    "[\n",
    "  {\n",
    "    \"sub\": \"<merged subject>\",\n",
    "    \"rel\": \"<original relationship description>\",\n",
    "    \"rel_type\": [\"<deduplicated type list>\"],\n",
    "    \"tactic\": [\"<deduplicated tactic list>\"],\n",
    "    \"obj\": \"<merged object>\"\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "#Final_Relationship_List_End#\n",
    "\n",
    "Below are the entities and relationships I extracted from multiple chunks:\n",
    "\n",
    "\"\"\"+str(merged_text)\n",
    "                \n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    return prompt_message\n",
    "\n",
    "model_dict = {\n",
    "    \"gpt4t\": 'gpt-4-turbo',\n",
    "    \"gpt41\": 'gpt-4.1',\n",
    "    \"gpt41mini\": 'gpt-4.1-mini',\n",
    "    \"gpt41nano\": 'gpt-4.1-nano',\n",
    "    \"gpt4o\": 'gpt-4o-2024-11-20',\n",
    "    \"gpt4omini\": 'gpt-4o-mini-2024-07-18',\n",
    "    \n",
    "    \"gpto4mini\": \"o4-mini\",\n",
    "    \"gpto3\": \"o3\",\n",
    "    \"gpto3mini\": 'o3-mini-2025-01-31',\n",
    "    \"gpto1\": 'o1-2024-12-17',\n",
    "    \"gpto1mini\": 'o1-mini-2024-09-12',\n",
    "    \n",
    "    \"hsr1\": 'deepseek-r1-250120',\n",
    "}\n",
    "\n",
    "reason_model=['o1','o3','o4']\n",
    "gpt_reason_model_for_json=['o1','o3','o4']\n",
    "reason_model_higheffort=['o3-mini','o4-mini']\n",
    "\n",
    "def tokenlen(text):\n",
    "    import tiktoken\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    token_integers = encoding.encode(str(text))\n",
    "    return len(token_integers)\n",
    "\n",
    "def ask_group_link(prompt_list, model, token=4096, temp=0.6, streamprint=False, max_workers=8, forcegpt=False):\n",
    "    if 'gpt' in model or 'hs' in model:\n",
    "        total_length = tokenlen(str(prompt_list))\n",
    "        runasgpt = False\n",
    "        if total_length < 10000:\n",
    "            runasgpt = True\n",
    "        else:\n",
    "            if not forcegpt:\n",
    "                print(\"The total length of the prompt is too long, total length is:\", total_length, \"set forcegpt as True\")\n",
    "            if forcegpt:\n",
    "                runasgpt = True\n",
    "        if runasgpt:\n",
    "            results = [None] * len(prompt_list)\n",
    "            with ThreadPoolExecutor(max_workers=128) as executor:\n",
    "                futures = {executor.submit(ask, prompt, token, temp, model, streamprint): idx for idx, prompt in enumerate(prompt_list)}\n",
    "                for future in as_completed(futures):\n",
    "                    idx = futures[future]\n",
    "                    try:\n",
    "                        results[idx] = future.result()\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "                        results[idx] = None\n",
    "            return results\n",
    "    else:\n",
    "        total_prompts = len(prompt_list)\n",
    "        results = [None] * total_prompts\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {executor.submit(ask, prompt, token, temp, model, streamprint): idx for idx, prompt in enumerate(prompt_list)}\n",
    "            for future in as_completed(futures):\n",
    "                idx = futures[future]\n",
    "                try:\n",
    "                    results[idx] = future.result()\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "                    results[idx] = None\n",
    "        return results\n",
    "\n",
    "def ask(prompt, token, temp, model, streamprint=True, mode=\"text\"):\n",
    "    api_key = \"EMPTY\"\n",
    "    if model.startswith(\"gpt\"):\n",
    "        api_key = \"<GPT_API_KEY>\"\n",
    "    if model.startswith(\"hs\"):\n",
    "        api_key = \"<HS_API_KEY>\"\n",
    "    if model.startswith(\"gpt\"):\n",
    "        api_base = 'https://api.openai.com/v1'\n",
    "    if '/' in model or 'local' in model:\n",
    "        api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "    if model == \"local\":\n",
    "        client = OpenAI(api_key=api_key, base_url=api_base)\n",
    "        models = client.models.list()\n",
    "        match = re.search(r\"id='(.*?)', created=\", str(models))\n",
    "        setmodel = match.group(1) if match else None\n",
    "    else:\n",
    "        setmodel = model_dict.get(model, '<MODEL_DICT_MISSING_KEY>')\n",
    "    if streamprint:\n",
    "        print('Using model:', setmodel)\n",
    "    if \"/\" in model or \"local\" in model or \"gpt\" in model:\n",
    "        client = OpenAI(api_key=api_key, base_url=api_base)\n",
    "        if mode == \"image\":\n",
    "            response = client.chat.completions.create(\n",
    "                messages=prompt,\n",
    "                model=setmodel,\n",
    "                max_tokens=token,\n",
    "                temperature=temp,\n",
    "            )\n",
    "            final_response = response.choices[0].message.content\n",
    "            print(f\"Response in image mode: {final_response}\")\n",
    "        if mode == \"text\":\n",
    "            if not any(reason in setmodel for reason in reason_model):\n",
    "                if streamprint:\n",
    "                    request_params = {\n",
    "                        \"model\": setmodel,\n",
    "                        \"messages\": prompt,\n",
    "                        \"stream\": True,\n",
    "                        \"max_tokens\": token,\n",
    "                        \"temperature\": temp,\n",
    "                    }\n",
    "                    stream = client.chat.completions.create(**request_params)\n",
    "                    final_response = \"\"\n",
    "                    for chunk in stream:\n",
    "                        if chunk.choices[0].delta.content:\n",
    "                            print(chunk.choices[0].delta.content, end=\"\")\n",
    "                            final_response += chunk.choices[0].delta.content\n",
    "                else:\n",
    "                    response = client.chat.completions.create(\n",
    "                        model=setmodel,\n",
    "                        messages=prompt,\n",
    "                        temperature=temp,\n",
    "                        max_tokens=token,\n",
    "                        stream=False,\n",
    "                    )\n",
    "                    final_response = response.choices[0].message.content\n",
    "            if any(reason in setmodel for reason in reason_model):\n",
    "                use_high_effort = any(a_model in setmodel for a_model in reason_model_higheffort)\n",
    "                reasoning_param = {\"effort\": \"high\"} if use_high_effort else {}\n",
    "                response = client.responses.create(\n",
    "                    model=setmodel,\n",
    "                    input=prompt,\n",
    "                    text={\"format\": {\"type\": \"text\"}},\n",
    "                    reasoning=reasoning_param,\n",
    "                    tools=[],\n",
    "                    max_output_tokens=token,\n",
    "                    top_p=1,\n",
    "                    store=False\n",
    "                )\n",
    "                final_response = response.output[1].content[0].text\n",
    "    if \"hsr1\" in model:\n",
    "        client = Ark(\n",
    "            api_key=api_key,\n",
    "            timeout=1800,\n",
    "        )\n",
    "        response = client.chat.completions.create(\n",
    "            model='deepseek-r1-250120',\n",
    "            messages=prompt,\n",
    "            temperature=temp,\n",
    "            max_tokens=token,\n",
    "        )\n",
    "        reasoning_content = getattr(response.choices[0].message, 'reasoning_content', \"\")\n",
    "        formatted_reasoning = f\"<think>{reasoning_content}</think>\" if reasoning_content else \"\"\n",
    "        final_response = f\"{formatted_reasoning}{response.choices[0].message.content}\"\n",
    "    if '/' in setmodel:\n",
    "        setmodel = setmodel.split('/')[-1]\n",
    "    record = {\n",
    "        \"prompt\": str(prompt),\n",
    "        \"setmodel\": setmodel,\n",
    "        \"temp\": temp,\n",
    "        \"max_tokens\": token,\n",
    "        \"response\": final_response\n",
    "    }\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime(\"%y%m%d\")\n",
    "    prompt_str = re.sub(r'\\W+', '', str(prompt))[:30]\n",
    "    folder_path = f\"<HISTORY_DIR>/{setmodel}/{date_str}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    max_digits = 100\n",
    "    current_digits = 10\n",
    "    while current_digits <= max_digits:\n",
    "        random_suffix = f\"{random.randint(10**(current_digits-1), 10**current_digits - 1)}\"\n",
    "        file_name = f\"{prompt_str}RANDOMKEY{random_suffix}.pkl\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if not os.path.exists(file_path):\n",
    "            with open(file_path, 'wb') as f:\n",
    "                pickle.dump(record, f)\n",
    "            break\n",
    "        current_digits += 1\n",
    "    if current_digits > max_digits:\n",
    "        raise RuntimeError(\"Cannot generate a unique filename; all options exhausted.\")\n",
    "    return final_response\n",
    "\n",
    "def process_article(full_text, mode, server):\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    try:\n",
    "        max_workers_forchunk = 1\n",
    "        if mode == 'o':\n",
    "            max_workers_forchunk = 16\n",
    "    except Exception as e:\n",
    "        print(\"process_article: Error in task mode configuration:\", str(e))\n",
    "        return None\n",
    "    try:\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            model_name=\"gpt-4\",\n",
    "            chunk_size=400,\n",
    "            chunk_overlap=40\n",
    "        )\n",
    "        chunks = text_splitter.split_text(full_text)\n",
    "    except Exception as e:\n",
    "        print(\"process_article: Error in text splitting:\", str(e))\n",
    "        return None\n",
    "    all_prompts = []\n",
    "    try:\n",
    "        for chunk in chunks:\n",
    "            try:\n",
    "                print(\"Chunk length:\", len(chunk), tokenlen(chunk))\n",
    "                all_prompts.append(chunk_prompt_maker((full_text, chunk)))\n",
    "            except Exception as inner_e:\n",
    "                print(\"process_article: Error generating prompt:\", str(inner_e))\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(\"process_article: Error iterating prompt generation:\", str(e))\n",
    "        return None\n",
    "    try:\n",
    "        ans = ask_group_link(\n",
    "            all_prompts,\n",
    "            token=32 * 1024,\n",
    "            temp=0.7,\n",
    "            model=\"local\",\n",
    "            streamprint=False,\n",
    "            max_workers=max_workers_forchunk,\n",
    "            forcegpt=True\n",
    "        )\n",
    "        if not ans or len(ans) == 0:\n",
    "            print(\"process_article: Error in getting chunk responses: returned empty list\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"process_article: Error in getting chunk responses:\", str(e))\n",
    "        return None\n",
    "    processed_answers = []\n",
    "    try:\n",
    "        for idx, response in enumerate(ans):\n",
    "            try:\n",
    "                parts = response.split(\"</think>\")\n",
    "                chunk_content = parts[1] if len(parts) > 1 else response\n",
    "                chunk_wrapper = [\n",
    "                    f\"\\n\\n[Chunk{idx}_START]\",\n",
    "                    chunk_content.strip(),\n",
    "                    f\"[Chunk{idx}_END]\\n\"\n",
    "                ]\n",
    "                processed_answers.append(\"\\n\".join(chunk_wrapper))\n",
    "            except Exception as inner_e:\n",
    "                print(f\"process_article: Error processing chunk {idx} response:\", str(inner_e))\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(\"process_article: Error iterating processed chunk responses:\", str(e))\n",
    "        return None\n",
    "    try:\n",
    "        merged_chunks_text = \"\".join([\n",
    "            f\"/* TOTAL {len(processed_answers)} CHUNKS START: */\\n\",\n",
    "            *processed_answers,\n",
    "            \"\\n/* END OF MERGED CHUNKS */\"\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(\"process_article: Error merging chunk responses:\", str(e))\n",
    "        return None\n",
    "    try:\n",
    "        merger_prompt = merger_prompt_maker(merged_chunks_text)\n",
    "        merger_prompt_list = [merger_prompt]\n",
    "        final_ans = ask_group_link(\n",
    "            merger_prompt_list,\n",
    "            token=32 * 1024,\n",
    "            temp=0.7,\n",
    "            model=\"local\",\n",
    "            streamprint=False,\n",
    "            max_workers=1,\n",
    "            forcegpt=True\n",
    "        )\n",
    "        if not final_ans or len(final_ans) == 0:\n",
    "            print(\"process_article: Error in getting final response: returned empty list\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"process_article: Error in getting final response:\", str(e))\n",
    "        return None\n",
    "    try:\n",
    "        if \"</think>\" in final_ans[0]:\n",
    "            parts = final_ans[0].split(\"</think>\")\n",
    "            if len(parts) > 1:\n",
    "                final_ans[0] = parts[1]\n",
    "    except Exception as e:\n",
    "        print(\"process_article: Error processing final response delimiter:\", str(e))\n",
    "        return None\n",
    "    return final_ans[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
