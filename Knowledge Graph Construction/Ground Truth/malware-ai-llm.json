{
  "relationshiplist": [
    {
      "sub": "Phishing email",
      "rel": "attached",
      "rel_type": [
        "delivers"
      ],
      "obj": "ZIP archive"
    },
    {
      "sub": "ZIP archive",
      "rel": "contains",
      "rel_type": [
        "consists-of"
      ],
      "obj": "LNK file"
    },
    {
      "sub": "LNK file",
      "rel": "runs",
      "rel_type": [
        "executes"
      ],
      "obj": "PowerShell script"
    },
    {
      "sub": "Large Language Model (LLM)",
      "rel": "can automatically generate",
      "rel_type": [
        "creates-or-generates"
      ],
      "obj": "PowerShell script"
    },
    {
      "sub": "HTML file",
      "rel": "downloaded",
      "rel_type": [
        "downloads"
      ],
      "obj": "Dunihi"
    }
  ],
  "entitylist": [
    {
      "name": "Large Language Model (LLM)",
      "type": "general-software",
      "alias": [
        "LLM",
        "generative AI",
        "AI tool"
      ],
      "mother entity": [
        "None"
      ]
    },
    {
      "name": "Phishing email",
      "type": "attack-pattern",
      "alias": [
        "None"
      ],
      "mother entity": [
        "None"
      ]
    },
    {
      "name": "Dunihi",
      "type": "malware",
      "alias": [
        "H-Worm",
        "Dunihi malware"
      ],
      "mother entity": [
        "None"
      ]
    },
    {
      "name": "ZIP archive",
      "type": "file",
      "alias": [
        "password-protected ZIP file"
      ],
      "mother entity": [
        "None"
      ]
    },
    {
      "name": "LNK file",
      "type": "file",
      "alias": [
        "malicious .lnk file"
      ],
      "mother entity": [
        "None"
      ]
    },
    {
      "name": "PowerShell script",
      "type": "file",
      "alias": [
        "LLM-generated PowerShell script"
      ],
      "mother entity": [
        "None"
      ]
    },
    {
      "name": "HTML file",
      "type": "file",
      "alias": [
        "LLM-generated HTML file"
      ],
      "mother entity": [
        "None"
      ]
    }
  ],
  "content": "Growing Number of Threats Leveraging AI\nThreat actors utilizing Large Language Model (LLM) AIs to generate code used in malware campaigns.\nSymantec has observed an increase in attacks that appear to leverage Large Language Models (LLMs) to generate malicious code used to download various payloads. \n\nLLMs are a form of generative AI designed to understand and generate human-like text. They have a wide range of applications, from assisting in writing to automating customer service. However, like many powerful technologies, LLMs can also be abused. \n\nRecent malware campaigns observed by Symantec involved phishing emails containing code used to download various payloads, including Rhadamanthys, NetSupport, CleanUpLoader (Broomstick, Oyster), ModiLoader (DBatLoader), LokiBot, and Dunihi (H-Worm). Analysis of the scripts used to deliver malware in these attacks suggests they were generated using LLMs.\n\nLLM Attack Chain Examples\nThe following example details a campaign targeting a wide range of sectors. The attacks involve phishing emails with attached .zip archives containing malicious .lnk files, which, once executed, trigger LLM-generated PowerShell scripts that lead to the deployment of malware. \n\nThe emails purport to relate to an urgent financing issue and contain a password-protected ZIP file, the password for which is also included in the email. \n\nFigure 1. Phishing email with an attached password-protected ZIP file\nFigure 1. Phishing email with an attached password-protected ZIP file\nThe ZIP file contains an LNK file that, when executed, runs a PowerShell script (Figure 2) likely generated using an LLM. Functions and variables are nicely formatted with leading single-line comments that use highly accurate grammar to explain their usage. \n\nFigure 2. LLM-generated PowerShell script\nFigure 2. LLM-generated PowerShell script\nThe script can easily be produced automatically using an LLM. We were able to produce similar results during our research using ChatGPT and a series of simple prompts (Figure 3).\n\nFigure 3. PowerShell script produced using ChatGPT\nFigure 3. PowerShell script produced using ChatGPT\nFinal payloads deployed in this campaign included the Rhadamanthys information-stealing malware and the CleanUpLoader backdoor (aka Broomstick, Oyster). \n\nLLM assist with phishing and payload delivery\nThe following example details the use of LLM-generated code to facilitate the phishing stage and the payload delivery stage of an attack. The following describes the attack chain events.\n\n1. Initial access: User receives a human-crafted phishing email with an attachment, mimicking an HR notification.\n\nFigure 4. Phishing email mimicking HR notification\nFigure 4. Phishing email mimicking HR notification\n2. Execution of LLM-generated script: Opening the malicious attachment executes an HTML file with embedded JavaScript that is highly likely generated by an LLM. This script is designed to download and execute additional payloads, although the webpage displayed in this case is fairly simple and the HTML behind it is small and quick to load.\n\nFigure 5. Webpage displayed during attack\nFigure 5. Webpage displayed during attack\nAnalysis of the HTML file, which facilitates a crucial link of the attack chain, reveals the characteristic features of an LLM-generated file (Figure 6).\n\nFigure 6. LLM-generated HTML file \nFigure 6. LLM-generated HTML file\nThe file itself can easily be produced automatically using an LLM, with little human effort required.\n\n3. Final payload download: By the time the user sees the page shown in Figure 5, the next stage payload – a loader for the Dunihi (H-Worm) malware – would have already been downloaded if the user has not configured their browser to ask for download permission first.\n\nSymantec also observed campaigns delivering the ModiLoader (DBatLoader) malware loader, the LokiBot information-stealing Trojan, and NetSupport remote access Trojan. The use of LLMs to generate HTML code used in these campaigns is also suspected. \n\nConclusion\nThe potential for AI to revolutionize our world is undeniable; however, it is also revolutionizing cybercrime. AI tools such as LLMs lower the barrier to entry for many threat actors, while increasing the level of sophistication for others. \n\nAs we have shown, AI-powered tools have given threat actors not only the ability to quickly craft convincing and targeted phishing emails, but also to generate malicious code that would normally require considerable expertise, time, and resources. \n\nIt is worth highlighting that AI is only going to get better. While the benefits for society are sure to be great, malicious actors will also benefit, using it to launch more sophisticated and effective attacks faster and at a larger scale. \n\nSymantec is at the forefront of cybersecurity, offering robust protection against the never-ending wave of new threats, including those recently observed, highly likely generated by LLMs. Our security solutions are equipped with advanced detection capabilities that block AI-based LLM-generated threats, with our threat hunting experts continuously monitoring the threat landscape, harvesting emerging threats, conducting detailed analysis, updating our automation models, and ensuring our customers are always protected.",
  "idorurl": "https://www.security.com/threat-intelligence/malware-ai-llm"
}